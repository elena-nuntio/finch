{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](end2end_mn.png)\n",
    "\n",
    "[End-To-End Memory Networks](https://arxiv.org/abs/1503.08895)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bunch import Bunch\n",
    "from copy import deepcopy\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json, pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Bunch({\n",
    "    'n_epochs': 20,\n",
    "    'batch_size': 64,\n",
    "    'hidden_dim': 64,\n",
    "    'dropout_rate': 0.3,\n",
    "    'n_hops': 2,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataLoader(object):\n",
    "    def __init__(self):\n",
    "        self.data = {\n",
    "            'size': None,\n",
    "            'val':{\n",
    "                'inputs': None,\n",
    "                'questions': None,\n",
    "                'answers': None,},\n",
    "            'len':{\n",
    "                'inputs_len': None,\n",
    "                'inputs_sent_len': None,\n",
    "                'questions_len': None,\n",
    "                'answers_len': None}\n",
    "        }\n",
    "        self.vocab = {\n",
    "            'size': None,\n",
    "            'word2idx': None,\n",
    "            'idx2word': None,\n",
    "        }\n",
    "        self.params = {\n",
    "            'vocab_size': None,\n",
    "            '<start>': None,\n",
    "            '<end>': None,\n",
    "            'max_input_len': None,\n",
    "            'max_sent_len': None,\n",
    "            'max_quest_len': None,\n",
    "            'max_answer_len': None,\n",
    "        }\n",
    "\n",
    "    def input_fn(self):\n",
    "        return tf.estimator.inputs.numpy_input_fn(\n",
    "            x = {\n",
    "                'inputs': self.data['val']['inputs'],\n",
    "                'questions': self.data['val']['questions'],\n",
    "                'inputs_len': self.data['len']['inputs_len'],\n",
    "                'inputs_sent_len': self.data['len']['inputs_sent_len'],\n",
    "                'questions_len': self.data['len']['questions_len'],\n",
    "                'answers_len': self.data['len']['answers_len']\n",
    "            },\n",
    "            y = self.data['val']['answers'] if self.is_training else None,\n",
    "            batch_size = args.batch_size,\n",
    "            num_epochs = args.n_epochs if self.is_training else 1,\n",
    "            shuffle = self.is_training)\n",
    "\n",
    "\n",
    "class DataLoader(BaseDataLoader):\n",
    "    def __init__(self, path, is_training, vocab=None, params=None):\n",
    "        super().__init__()\n",
    "        data, lens = self.load_data(path)\n",
    "        if is_training:\n",
    "            self.build_vocab(data)\n",
    "        else:\n",
    "            self.demo = data\n",
    "            self.vocab = vocab\n",
    "            self.params = deepcopy(params)\n",
    "        self.is_training = is_training\n",
    "        self.padding(data, lens)\n",
    "\n",
    "\n",
    "    def load_data(self, path):\n",
    "        data, lens = bAbI_data_load(path)\n",
    "        self.data['size'] = len(data[0])\n",
    "        return data, lens\n",
    "\n",
    "\n",
    "    def build_vocab(self, data):\n",
    "        signals = ['<pad>', '<unk>', '<start>', '<end>']\n",
    "        inputs, questions, answers = data\n",
    "        i_words = [w for facts in inputs for fact in facts for w in fact if w != '<end>']\n",
    "        q_words = [w for question in questions for w in question]\n",
    "        a_words = [w for answer in answers for w in answer if w != '<end>']\n",
    "        words = list(set(i_words + q_words + a_words))\n",
    "        self.params['vocab_size'] = len(words) + 4\n",
    "        self.params['<start>'] = 2\n",
    "        self.params['<end>'] = 3\n",
    "        self.vocab['word2idx'] = {word: idx for idx, word in enumerate(signals + words)}\n",
    "        self.vocab['idx2word'] = {idx: word for word, idx in self.vocab['word2idx'].items()}\n",
    "        \n",
    "\n",
    "    def padding(self, data, lens):\n",
    "        inputs_len, inputs_sent_len, questions_len, answers_len = lens\n",
    "\n",
    "        if self.is_training:\n",
    "            self.params['max_input_len'] = max(inputs_len)\n",
    "            self.params['max_sent_len'] = max([fact_len for batch in inputs_sent_len for fact_len in batch])\n",
    "            self.params['max_quest_len'] = max(questions_len)\n",
    "            self.params['max_answer_len'] = max(answers_len)\n",
    "\n",
    "        self.data['len']['inputs_len'] = np.array(inputs_len)\n",
    "        for batch in inputs_sent_len:\n",
    "            batch += [0] * (self.params['max_input_len'] - len(batch))\n",
    "        self.data['len']['inputs_sent_len'] = np.array(inputs_sent_len)\n",
    "        self.data['len']['questions_len'] = np.array(questions_len)\n",
    "        self.data['len']['answers_len'] = np.array(answers_len)\n",
    "        \n",
    "        inputs, questions, answers = deepcopy(data)\n",
    "        for facts in inputs:\n",
    "            for sentence in facts:\n",
    "                for i in range(len(sentence)):\n",
    "                    sentence[i] = self.vocab['word2idx'].get(sentence[i], self.vocab['word2idx']['<unk>'])\n",
    "                sentence += [0] * (self.params['max_sent_len'] - len(sentence))\n",
    "            paddings = [0] * self.params['max_sent_len']\n",
    "            facts += [paddings] * (self.params['max_input_len'] - len(facts))\n",
    "        for question in questions:\n",
    "            for i in range(len(question)):\n",
    "                question[i] = self.vocab['word2idx'].get(question[i], self.vocab['word2idx']['<unk>'])\n",
    "            question += [0] * (self.params['max_quest_len'] - len(question))\n",
    "        for answer in answers:\n",
    "            for i in range(len(answer)):\n",
    "                answer[i] = self.vocab['word2idx'].get(answer[i], self.vocab['word2idx']['<unk>'])\n",
    "\n",
    "        self.data['val']['inputs'] = np.array(inputs)\n",
    "        self.data['val']['questions'] = np.array(questions)\n",
    "        self.data['val']['answers'] = np.array(answers)\n",
    "\n",
    "\n",
    "def bAbI_data_load(path, END=['<end>']):\n",
    "    inputs = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    inputs_len = []\n",
    "    inputs_sent_len = []\n",
    "    questions_len = []\n",
    "    answers_len = []\n",
    "\n",
    "    for d in open(path):\n",
    "        index = d.split(' ')[0]\n",
    "        if index == '1':\n",
    "            fact = []\n",
    "        if '?' in d:\n",
    "            temp = d.split('\\t')\n",
    "            q = temp[0].strip().replace('?', '').split(' ')[1:] + ['?']\n",
    "            a = temp[1].split() + END\n",
    "            fact_copied = deepcopy(fact)\n",
    "            inputs.append(fact_copied)\n",
    "            questions.append(q)\n",
    "            answers.append(a)\n",
    "\n",
    "            inputs_len.append(len(fact_copied))\n",
    "            inputs_sent_len.append([len(s) for s in fact_copied])\n",
    "            questions_len.append(len(q))\n",
    "            answers_len.append(len(a))\n",
    "        else:\n",
    "            tokens = d.replace('.', '').replace('\\n', '').split(' ')[1:] + END\n",
    "            fact.append(tokens)\n",
    "    return [inputs, questions, answers], [inputs_len, inputs_sent_len, questions_len, answers_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    if labels is None:\n",
    "        labels = tf.placeholder(tf.int64, [None, params['max_answer_len']])\n",
    "\n",
    "    logits = forward(features, params, is_training=True, reuse=False,\n",
    "                     seq_inputs=shift_right(labels, params))\n",
    "    \n",
    "    predicted_ids = forward(features, params, is_training=False, reuse=True)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predicted_ids)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        loss_op = tf.reduce_mean(tf.contrib.seq2seq.sequence_loss(\n",
    "            logits=logits, targets=labels, weights=tf.ones_like(labels, tf.float32)))\n",
    "\n",
    "        train_op = tf.train.AdamOptimizer().minimize(loss_op,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss_op, train_op=train_op)\n",
    "\n",
    "\n",
    "def hop_forward(features, question, memory_o, memory_i, response_proj,\n",
    "                params, is_training, reuse):\n",
    "    match = tf.matmul(question, tf.transpose(memory_i, [0,2,1]))\n",
    "\n",
    "    match = pre_softmax_masking(match, features['inputs_len'], params['max_input_len'])\n",
    "\n",
    "    match = tf.nn.softmax(match)       # (batch, question_maxlen, input_maxlen)\n",
    "\n",
    "    match = post_softmax_masking(match, features['questions_len'], params['max_quest_len'])\n",
    "\n",
    "    response = tf.matmul(match, memory_o)\n",
    "\n",
    "    response = response_proj(tf.concat([response, question], -1))\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "def forward(features, params, is_training, reuse, seq_inputs=None):\n",
    "    with tf.variable_scope('questions', reuse=reuse):\n",
    "        question = quest_mem(features['questions'], params, is_training)\n",
    "        \n",
    "    with tf.variable_scope('memory_o', reuse=reuse):\n",
    "        memory_o = input_mem(features['inputs'], params, is_training)\n",
    "    \n",
    "    with tf.variable_scope('memory_i', reuse=reuse):\n",
    "        memory_i = input_mem(features['inputs'], params, is_training)\n",
    "    \n",
    "    with tf.variable_scope('interaction', reuse=reuse):\n",
    "        response_proj = tf.layers.Dense(args.hidden_dim)\n",
    "        \n",
    "        for _ in range(args['n_hops']):\n",
    "            answer = hop_forward(features,\n",
    "                                 question,\n",
    "                                 memory_o,\n",
    "                                 memory_i,\n",
    "                                 response_proj,\n",
    "                                 params,\n",
    "                                 is_training,\n",
    "                                 reuse)\n",
    "            question = answer\n",
    "    \n",
    "    with tf.variable_scope('memory_o', reuse=True):\n",
    "        embedding = tf.get_variable('lookup_table')\n",
    "    \n",
    "    with tf.variable_scope('answer', reuse=reuse):\n",
    "        output = answer_module(features, params, answer, embedding, is_training, seq_inputs)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def input_mem(x, params, is_training):\n",
    "    x = embed_seq(x, params)\n",
    "    x = tf.layers.dropout(x, args.dropout_rate, training=is_training)\n",
    "    pos = position_encoding(params['max_sent_len'], args.hidden_dim)\n",
    "    x = tf.reduce_sum(x * pos, 2)\n",
    "    return x\n",
    "\n",
    "\n",
    "def quest_mem(x, params, is_training):\n",
    "    x = embed_seq(x, params)\n",
    "    x = tf.layers.dropout(x, args.dropout_rate, training=is_training)\n",
    "    pos = position_encoding(params['max_quest_len'], args.hidden_dim)\n",
    "    return (x * pos)\n",
    "\n",
    "\n",
    "def answer_module(features, params, answer, embedding, is_training, seq_inputs=None):\n",
    "    cell = GRU()\n",
    "    vocab_proj = tf.layers.Dense(params['vocab_size'])\n",
    "    state_proj = tf.layers.Dense(args.hidden_dim)\n",
    "    \n",
    "    init_state = state_proj(tf.layers.flatten(answer))\n",
    "    init_state = tf.layers.dropout(init_state, args.dropout_rate, training=is_training)\n",
    "\n",
    "    if is_training:\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            inputs = tf.nn.embedding_lookup(embedding, seq_inputs),\n",
    "            sequence_length = tf.to_int32(features['answers_len']))\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            cell = cell,\n",
    "            helper = helper,\n",
    "            initial_state = init_state,\n",
    "            output_layer = vocab_proj)\n",
    "        decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder = decoder)\n",
    "        return decoder_output.rnn_output\n",
    "    else:\n",
    "        helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            embedding = embedding,\n",
    "            start_tokens = tf.tile(\n",
    "                tf.constant([params['<start>']], dtype=tf.int32), [tf.shape(init_state)[0]]),\n",
    "            end_token = params['<end>'])\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            cell = cell,\n",
    "            helper = helper,\n",
    "            initial_state = init_state,\n",
    "            output_layer = vocab_proj)\n",
    "        decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder = decoder,\n",
    "            maximum_iterations = params['max_answer_len'])\n",
    "        return decoder_output.sample_id\n",
    "\n",
    "\n",
    "def pre_softmax_masking(x, seq_len, max_seq_len):\n",
    "    paddings = tf.fill(tf.shape(x), float('-inf'))\n",
    "    T = x.get_shape().as_list()[1]\n",
    "    masks = tf.sequence_mask(seq_len, max_seq_len, dtype=tf.float32)\n",
    "    masks = tf.tile(tf.expand_dims(masks, 1), [1, T, 1])\n",
    "    return tf.where(tf.equal(masks, 0), paddings, x)\n",
    "\n",
    "\n",
    "def post_softmax_masking(x, seq_len, max_seq_len):\n",
    "    T = x.get_shape().as_list()[-1]\n",
    "    masks = tf.sequence_mask(seq_len, max_seq_len, dtype=tf.float32)\n",
    "    masks = tf.tile(tf.expand_dims(masks, -1), [1, 1, T])\n",
    "    return (x * masks)\n",
    "\n",
    "\n",
    "def shift_right(x, params):\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    start = tf.to_int64(tf.fill([batch_size, 1], params['<start>']))\n",
    "    return tf.concat([start, x[:, :-1]], 1)\n",
    "\n",
    "\n",
    "def embed_seq(x, params, zero_pad=True):\n",
    "    lookup_table = tf.get_variable('lookup_table', [params['vocab_size'], args.hidden_dim], tf.float32)\n",
    "    if zero_pad:\n",
    "        lookup_table = tf.concat((tf.zeros([1, args.hidden_dim]), lookup_table[1:, :]), axis=0)\n",
    "    return tf.nn.embedding_lookup(lookup_table, x)\n",
    "\n",
    "\n",
    "def position_encoding(sentence_size, embedding_size):\n",
    "    encoding = np.ones((embedding_size, sentence_size), dtype=np.float32)\n",
    "    ls = sentence_size + 1\n",
    "    le = embedding_size + 1\n",
    "    for i in range(1, le):\n",
    "        for j in range(1, ls):\n",
    "            encoding[i-1, j-1] = (i - (le-1)/2) * (j - (ls-1)/2)\n",
    "    encoding = 1 + 4 * encoding / embedding_size / sentence_size\n",
    "    return np.transpose(encoding)\n",
    "\n",
    "\n",
    "def GRU(rnn_size=None):\n",
    "    rnn_size = args.hidden_dim if rnn_size is None else rnn_size\n",
    "    return tf.nn.rnn_cell.GRUCell(\n",
    "        rnn_size, kernel_initializer=tf.orthogonal_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"n_epochs\": 20,\n",
      "    \"batch_size\": 64,\n",
      "    \"hidden_dim\": 64,\n",
      "    \"dropout_rate\": 0.3,\n",
      "    \"n_hops\": 2\n",
      "}\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmp4qtkjy4q\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmp4qtkjy4q', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11fd26828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmp4qtkjy4q/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.8352404, step = 1\n",
      "INFO:tensorflow:global_step/sec: 12.735\n",
      "INFO:tensorflow:loss = 0.56435734, step = 101 (7.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2118\n",
      "INFO:tensorflow:loss = 0.50788563, step = 201 (7.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9296\n",
      "INFO:tensorflow:loss = 0.37739548, step = 301 (7.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6062\n",
      "INFO:tensorflow:loss = 0.28193197, step = 401 (7.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.467\n",
      "INFO:tensorflow:loss = 0.22447741, step = 501 (7.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5511\n",
      "INFO:tensorflow:loss = 0.21542503, step = 601 (6.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4308\n",
      "INFO:tensorflow:loss = 0.2793676, step = 701 (6.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.547\n",
      "INFO:tensorflow:loss = 0.20185472, step = 801 (6.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7698\n",
      "INFO:tensorflow:loss = 0.19279633, step = 901 (6.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5267\n",
      "INFO:tensorflow:loss = 0.16853529, step = 1001 (7.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4708\n",
      "INFO:tensorflow:loss = 0.25292093, step = 1101 (7.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0071\n",
      "INFO:tensorflow:loss = 0.18823385, step = 1201 (7.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3961\n",
      "INFO:tensorflow:loss = 0.25262076, step = 1301 (7.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1026\n",
      "INFO:tensorflow:loss = 0.17636803, step = 1401 (7.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8978\n",
      "INFO:tensorflow:loss = 0.14284092, step = 1501 (7.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3287\n",
      "INFO:tensorflow:loss = 0.1815162, step = 1601 (7.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9211\n",
      "INFO:tensorflow:loss = 0.16306801, step = 1701 (7.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7124\n",
      "INFO:tensorflow:loss = 0.18584777, step = 1801 (6.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5359\n",
      "INFO:tensorflow:loss = 0.13852467, step = 1901 (6.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3347\n",
      "INFO:tensorflow:loss = 0.20099796, step = 2001 (6.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2656\n",
      "INFO:tensorflow:loss = 0.15976728, step = 2101 (7.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7225\n",
      "INFO:tensorflow:loss = 0.12295742, step = 2201 (8.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8655\n",
      "INFO:tensorflow:loss = 0.11582595, step = 2301 (7.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4903\n",
      "INFO:tensorflow:loss = 0.1314395, step = 2401 (6.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6461\n",
      "INFO:tensorflow:loss = 0.14324717, step = 2501 (6.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5408\n",
      "INFO:tensorflow:loss = 0.10408843, step = 2601 (6.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4649\n",
      "INFO:tensorflow:loss = 0.11798013, step = 2701 (8.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3151\n",
      "INFO:tensorflow:loss = 0.09021413, step = 2801 (7.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0724\n",
      "INFO:tensorflow:loss = 0.11275349, step = 2901 (7.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0805\n",
      "INFO:tensorflow:loss = 0.12031268, step = 3001 (7.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6093\n",
      "INFO:tensorflow:loss = 0.22226116, step = 3101 (7.348 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3125 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmp4qtkjy4q/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.13226146.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmp4qtkjy4q/model.ckpt-3125\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Testing Accuracy: 0.919\n",
      "\n",
      "[['Fred', 'picked', 'up', 'the', 'football', 'there', '<end>'],\n",
      " ['Fred', 'gave', 'the', 'football', 'to', 'Jeff', '<end>'],\n",
      " ['Bill', 'went', 'back', 'to', 'the', 'bathroom', '<end>'],\n",
      " ['Jeff', 'grabbed', 'the', 'milk', 'there', '<end>'],\n",
      " ['Jeff', 'gave', 'the', 'football', 'to', 'Fred', '<end>'],\n",
      " ['Fred', 'handed', 'the', 'football', 'to', 'Jeff', '<end>'],\n",
      " ['Jeff', 'handed', 'the', 'football', 'to', 'Fred', '<end>'],\n",
      " ['Fred', 'gave', 'the', 'football', 'to', 'Jeff', '<end>']]\n",
      "\n",
      "Question: ['Who', 'did', 'Fred', 'give', 'the', 'football', 'to', '?']\n",
      "\n",
      "Prediction: ['Jeff', '<end>']\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    print(json.dumps(args, indent=4))\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        path='../temp/qa5_three-arg-relations_train.txt',\n",
    "        is_training=True)\n",
    "    test_dl = DataLoader(\n",
    "        path='../temp/qa5_three-arg-relations_test.txt',\n",
    "        is_training=False, vocab=train_dl.vocab, params=train_dl.params)\n",
    "\n",
    "    model = tf.estimator.Estimator(model_fn, params=train_dl.params)\n",
    "    model.train(train_dl.input_fn())\n",
    "    gen = model.predict(test_dl.input_fn())\n",
    "    preds = np.concatenate(list(gen))\n",
    "    preds = np.reshape(preds, [test_dl.data['size'], 2])\n",
    "    print('Testing Accuracy:', (test_dl.data['val']['answers'][:, 0] == preds[:, 0]).mean())\n",
    "    demo(test_dl.demo, test_dl.vocab['idx2word'], preds)\n",
    "\n",
    "\n",
    "def demo(demo, idx2word, ids, demo_idx=3):\n",
    "    demo_i, demo_q, demo_a = demo\n",
    "    print()\n",
    "    pprint.pprint(demo_i[demo_idx])\n",
    "    print()\n",
    "    print('Question:', demo_q[demo_idx])\n",
    "    print()\n",
    "    print('Prediction:', [idx2word[id] for id in ids[demo_idx]])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
