{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'embed_dims': 15,\n",
    "    'rnn_size': 50,\n",
    "    'num_layers': 1,\n",
    "    'beam_width': 5,\n",
    "    'clip_norm': 5.0,\n",
    "    'batch_size': 128,\n",
    "    'n_epochs': 60,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "    \n",
    "def build_map(data):\n",
    "    specials = ['<PAD>', '<GO>',  '<EOS>', '<UNK>']\n",
    "    chars = list(set([char for line in data.split('\\n') for char in line]))\n",
    "    idx2char = {idx: char for idx, char in enumerate(specials + chars)}\n",
    "    char2idx = {char: idx for idx, char in idx2char.items()}\n",
    "    return idx2char, char2idx\n",
    "\n",
    "\n",
    "def preprocess_data():\n",
    "    source = read_data('../temp/letters_source.txt')\n",
    "    target = read_data('../temp/letters_target.txt')\n",
    "\n",
    "    PARAMS['src_idx2char'], PARAMS['src_char2idx'] = build_map(source)\n",
    "    PARAMS['tgt_idx2char'], PARAMS['tgt_char2idx'] = build_map(target)\n",
    "\n",
    "    src_idx = [[PARAMS['src_char2idx'].get(char, 3) for char in line] for line in source.split('\\n')]\n",
    "    tgt_idx = [[PARAMS['tgt_char2idx'].get(char, 3) for char in line]+[2] for line in target.split('\\n')]\n",
    "\n",
    "    return src_idx, tgt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sent_batch(sent_batch):\n",
    "    max_sent_len = max([len(sent) for sent in sent_batch])\n",
    "    padded_seqs = [(sent + [0]*(max_sent_len - len(sent))) for sent in sent_batch]\n",
    "    return padded_seqs\n",
    "\n",
    "\n",
    "def next_train_batch(src_idx, tgt_idx):\n",
    "    for i in range(0, len(src_idx), PARAMS['batch_size']):\n",
    "        padded_src = pad_sent_batch(src_idx[i: i+PARAMS['batch_size']])\n",
    "        padded_tgt = pad_sent_batch(tgt_idx[i: i+PARAMS['batch_size']])\n",
    "        yield padded_src, padded_tgt\n",
    "\n",
    "        \n",
    "def train_input_fn(src_idx, tgt_idx):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: next_train_batch(src_idx, tgt_idx),\n",
    "        (tf.int32, tf.int32),\n",
    "        (tf.TensorShape([None, None]), tf.TensorShape([None, None])))\n",
    "    dataset = dataset.repeat(PARAMS['n_epochs'])\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_grads(loss):\n",
    "    variables = tf.trainable_variables()\n",
    "    grads = tf.gradients(loss, variables)\n",
    "    clipped_grads, _ = tf.clip_by_global_norm(grads, PARAMS['clip_norm'])\n",
    "    return zip(clipped_grads, variables)\n",
    "\n",
    "\n",
    "def rnn_cell():\n",
    "    def cell_fn():\n",
    "        cell = tf.nn.rnn_cell.GRUCell(PARAMS['rnn_size'],\n",
    "                                      kernel_initializer=tf.orthogonal_initializer())\n",
    "        return cell\n",
    "    return tf.nn.rnn_cell.MultiRNNCell([cell_fn() for _ in range(PARAMS['num_layers'])])\n",
    "\n",
    "\n",
    "def dec_cell(enc_out, enc_seq_len):\n",
    "    attention = tf.contrib.seq2seq.BahdanauAttention(\n",
    "        num_units = PARAMS['rnn_size'],\n",
    "        memory = enc_out,\n",
    "        memory_sequence_length = enc_seq_len)\n",
    "    \n",
    "    return tf.contrib.seq2seq.AttentionWrapper(\n",
    "        cell = rnn_cell(),\n",
    "        attention_mechanism = attention,\n",
    "        attention_layer_size = PARAMS['rnn_size'])\n",
    "\n",
    "\n",
    "def dec_input(labels):\n",
    "    x = tf.fill([tf.shape(labels)[0], 1], PARAMS['tgt_char2idx']['<GO>'])\n",
    "    x = tf.to_int32(x)\n",
    "    return tf.concat([x, labels[:, :-1]], 1)\n",
    "\n",
    "\n",
    "def forward(inputs, labels, reuse, is_training):\n",
    "    enc_seq_len = tf.count_nonzero(inputs, 1, dtype=tf.int32)\n",
    "    dec_seq_len = tf.count_nonzero(labels, 1, dtype=tf.int32)\n",
    "    batch_sz = tf.shape(inputs)[0]\n",
    "    \n",
    "    with tf.variable_scope('Encoder', reuse=reuse):\n",
    "        embedding = tf.get_variable('lookup_table',\n",
    "                                    [len(PARAMS['src_char2idx']), PARAMS['embed_dims']])\n",
    "        x = tf.nn.embedding_lookup(embedding, inputs)\n",
    "        enc_out, enc_state = tf.nn.dynamic_rnn(rnn_cell(), x, enc_seq_len, dtype=tf.float32)\n",
    "        \n",
    "    with tf.variable_scope('Decoder', reuse=reuse):\n",
    "        output_proj = tf.layers.Dense(len(PARAMS['tgt_char2idx']))\n",
    "        \n",
    "        enc_out_t = tf.contrib.seq2seq.tile_batch(enc_out, PARAMS['beam_width'])\n",
    "        enc_state_t = tf.contrib.seq2seq.tile_batch(enc_state, PARAMS['beam_width'])\n",
    "        enc_seq_len_t = tf.contrib.seq2seq.tile_batch(enc_seq_len, PARAMS['beam_width'])\n",
    "        \n",
    "        _e_o = tf.cond(tf.constant(is_training), lambda: enc_out, lambda: enc_out_t)\n",
    "        _e_s_l = tf.cond(tf.constant(is_training), lambda: enc_seq_len, lambda: enc_seq_len_t)\n",
    "        \n",
    "        cell = dec_cell(_e_o, _e_s_l)\n",
    "        \n",
    "        if is_training:\n",
    "            init_state = cell.zero_state(batch_sz, tf.float32).clone(\n",
    "                cell_state=enc_state)\n",
    "            \n",
    "            helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                inputs = tf.nn.embedding_lookup(embedding, dec_input(labels)),\n",
    "                sequence_length = dec_seq_len)\n",
    "            decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                cell = cell,\n",
    "                helper = helper,\n",
    "                initial_state = init_state,\n",
    "                output_layer = output_proj)\n",
    "            decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                decoder = decoder,\n",
    "                maximum_iterations = tf.reduce_max(dec_seq_len))\n",
    "            return decoder_output.rnn_output\n",
    "        else:\n",
    "            init_state = cell.zero_state(batch_sz*PARAMS['beam_width'], tf.float32).clone(\n",
    "                cell_state=enc_state_t)\n",
    "            \n",
    "            decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                cell = cell,\n",
    "                embedding = embedding,\n",
    "                start_tokens = tf.tile(tf.constant([PARAMS['tgt_char2idx']['<GO>']], tf.int32),\n",
    "                                       [batch_sz]),\n",
    "                end_token = PARAMS['tgt_char2idx']['<EOS>'],\n",
    "                initial_state = init_state,\n",
    "                beam_width = PARAMS['beam_width'],\n",
    "                output_layer = output_proj)\n",
    "            decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                decoder = decoder)\n",
    "            return decoder_output.predicted_ids[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    if labels is None:\n",
    "        labels = tf.placeholder(tf.int32, [None, None])\n",
    "    \n",
    "    logits = forward(features, labels, reuse=False, is_training=True)\n",
    "    \n",
    "    pred_ids = forward(features, labels, reuse=True, is_training=False)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_ids)\n",
    "        \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        loss_op = tf.contrib.seq2seq.sequence_loss(logits = logits,\n",
    "                                                   targets = labels,\n",
    "                                                   weights = tf.to_float(tf.sign(labels)))\n",
    "        train_op = tf.train.AdamOptimizer().apply_gradients(\n",
    "            clip_grads(loss_op),\n",
    "            global_step = tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss_op, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpeiu7hwdc\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpeiu7hwdc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11d90ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x11d8ff6a8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpeiu7hwdc/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.4019551, step = 1\n",
      "INFO:tensorflow:global_step/sec: 30.1106\n",
      "INFO:tensorflow:loss = 2.0150197, step = 101 (3.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.5646\n",
      "INFO:tensorflow:loss = 1.3260248, step = 201 (2.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.4598\n",
      "INFO:tensorflow:loss = 1.0011088, step = 301 (2.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8084\n",
      "INFO:tensorflow:loss = 0.6851337, step = 401 (2.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8273\n",
      "INFO:tensorflow:loss = 0.47160637, step = 501 (2.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.5382\n",
      "INFO:tensorflow:loss = 0.3133647, step = 601 (2.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.2796\n",
      "INFO:tensorflow:loss = 0.18578173, step = 701 (2.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.7711\n",
      "INFO:tensorflow:loss = 0.10916492, step = 801 (2.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.524\n",
      "INFO:tensorflow:loss = 0.09122529, step = 901 (2.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.6154\n",
      "INFO:tensorflow:loss = 0.056705423, step = 1001 (2.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.5957\n",
      "INFO:tensorflow:loss = 0.051408697, step = 1101 (2.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.2091\n",
      "INFO:tensorflow:loss = 0.037686296, step = 1201 (2.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8496\n",
      "INFO:tensorflow:loss = 0.0471876, step = 1301 (2.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.709\n",
      "INFO:tensorflow:loss = 0.021481367, step = 1401 (2.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.1306\n",
      "INFO:tensorflow:loss = 0.007309763, step = 1501 (2.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.9569\n",
      "INFO:tensorflow:loss = 0.014765735, step = 1601 (2.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.6064\n",
      "INFO:tensorflow:loss = 0.012060761, step = 1701 (2.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.9051\n",
      "INFO:tensorflow:loss = 0.010941342, step = 1801 (2.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.6636\n",
      "INFO:tensorflow:loss = 0.0063722627, step = 1901 (2.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.0188\n",
      "INFO:tensorflow:loss = 0.00692931, step = 2001 (2.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.2863\n",
      "INFO:tensorflow:loss = 0.012286892, step = 2101 (2.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8961\n",
      "INFO:tensorflow:loss = 0.033218615, step = 2201 (2.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.0172\n",
      "INFO:tensorflow:loss = 0.008165095, step = 2301 (2.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.1265\n",
      "INFO:tensorflow:loss = 0.008415845, step = 2401 (2.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.9577\n",
      "INFO:tensorflow:loss = 0.004512885, step = 2501 (2.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.7421\n",
      "INFO:tensorflow:loss = 0.0036923955, step = 2601 (2.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.3656\n",
      "INFO:tensorflow:loss = 0.0033016996, step = 2701 (2.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.6625\n",
      "INFO:tensorflow:loss = 0.001996203, step = 2801 (2.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.1436\n",
      "INFO:tensorflow:loss = 0.002106982, step = 2901 (2.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.4591\n",
      "INFO:tensorflow:loss = 0.002349384, step = 3001 (2.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.5394\n",
      "INFO:tensorflow:loss = 0.0018591709, step = 3101 (2.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.4988\n",
      "INFO:tensorflow:loss = 0.0023564186, step = 3201 (2.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.6449\n",
      "INFO:tensorflow:loss = 0.0013907587, step = 3301 (2.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.9223\n",
      "INFO:tensorflow:loss = 0.00123735, step = 3401 (2.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.0975\n",
      "INFO:tensorflow:loss = 0.0010593651, step = 3501 (2.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.6692\n",
      "INFO:tensorflow:loss = 0.0010257858, step = 3601 (2.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.2692\n",
      "INFO:tensorflow:loss = 0.00097174913, step = 3701 (2.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.1712\n",
      "INFO:tensorflow:loss = 0.0008759702, step = 3801 (2.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.397\n",
      "INFO:tensorflow:loss = 0.0009802928, step = 3901 (2.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.1719\n",
      "INFO:tensorflow:loss = 0.0007434481, step = 4001 (2.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.0034\n",
      "INFO:tensorflow:loss = 0.00055698236, step = 4101 (2.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.4154\n",
      "INFO:tensorflow:loss = 0.00068855146, step = 4201 (2.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.3993\n",
      "INFO:tensorflow:loss = 0.0008466127, step = 4301 (2.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7035\n",
      "INFO:tensorflow:loss = 0.0005533729, step = 4401 (2.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.4235\n",
      "INFO:tensorflow:loss = 0.00049345376, step = 4501 (2.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.283\n",
      "INFO:tensorflow:loss = 0.00036261938, step = 4601 (2.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.8784\n",
      "INFO:tensorflow:loss = 0.00032582198, step = 4701 (2.639 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4740 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpeiu7hwdc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.1282684e-05.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpeiu7hwdc/model.ckpt-4740\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "IN: apple\n",
      "OUT: a e l p p <EOS> <EOS> <EOS>\n",
      "\n",
      "IN: common\n",
      "OUT: c m m n o o <EOS> <EOS>\n",
      "\n",
      "IN: zhedong\n",
      "OUT: d e g h n o z <EOS>\n"
     ]
    }
   ],
   "source": [
    "def infe_inps(str_li):\n",
    "    max_len = max([len(s) for s in str_li])\n",
    "    xs = [[PARAMS['src_char2idx'].get(c, 3) for c in s] for s in str_li]\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(xs, max_len, padding='post')\n",
    "\n",
    "\n",
    "def demo(xs, preds):\n",
    "    for x, pred in zip(xs, preds):\n",
    "        print('\\nIN: {}'.format(x))\n",
    "        print('OUT: {}'.format(' '.join([PARAMS['tgt_idx2char'][i] for i in pred])))\n",
    "    \n",
    "\n",
    "def main():\n",
    "    src_idx, tgt_idx = preprocess_data()\n",
    "    \n",
    "    estimator = tf.estimator.Estimator(model_fn)\n",
    "    \n",
    "    estimator.train(lambda: train_input_fn(src_idx, tgt_idx))\n",
    "    \n",
    "    xs = ['apple', 'common', 'zhedong']\n",
    "    \n",
    "    preds = list(estimator.predict(tf.estimator.inputs.numpy_input_fn(\n",
    "        x = infe_inps(xs),\n",
    "        shuffle = False)))\n",
    "    \n",
    "    demo(xs, preds)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
